{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\ud83c\udfe0 Home","text":"\ud83d\ude80 GoLangGraph <p>Build Intelligent AI Agent Workflows with Go</p> <ul> <li> <p> \ud83d\ude80 Quick Start</p> <p>Get up and running with GoLangGraph in minutes. Build your first AI agent workflow with just a few lines of code.</p> <p> Getting Started</p> </li> <li> <p> \ud83d\udcca Graph Workflows</p> <p>Design complex AI workflows as directed graphs. Each node represents a computational unit, edges define execution flow.</p> <p> Learn More</p> </li> <li> <p> \ud83d\udcbe Persistence &amp; RAG</p> <p>Built-in support for PostgreSQL, Redis, and vector databases. Perfect for RAG applications and long-running workflows.</p> <p> Persistence Guide</p> </li> <li> <p> \ud83d\udd27 Rich Tooling</p> <p>Comprehensive debugging, visualization, and monitoring tools. Built-in support for popular LLM providers.</p> <p> Tools &amp; Extensions</p> </li> </ul>"},{"location":"#what-is-golanggraph","title":"\ud83c\udfaf What is GoLangGraph?","text":"<p>GoLangGraph is a powerful Go framework for building AI agent workflows with graph-based execution. It provides a clean, type-safe API for creating complex multi-agent systems, RAG applications, and intelligent workflows.</p> <p>\ud83d\udca1 Perfect for: Building production-ready AI applications that require reliability, performance, and scalability.</p>"},{"location":"#key-features","title":"\u2728 Key Features","text":"<ul> <li> <p>\ud83d\ude80 Graph-Based Execution</p> <p>Design workflows as directed graphs with nodes and edges. Build complex logic with simple, composable components.</p> </li> <li> <p>\ud83d\udd04 State Management</p> <p>Thread-safe state containers with automatic persistence. Never lose your workflow progress.</p> </li> <li> <p>\ud83e\udd16 Multi-Agent Support</p> <p>Build complex multi-agent systems with ease. Coordinate multiple AI agents working together.</p> </li> <li> <p>\ud83d\uddc4\ufe0f Database Integration</p> <p>Native support for PostgreSQL, Redis, and vector databases. Perfect for RAG applications.</p> </li> <li> <p>\ud83d\udd27 Rich Tooling</p> <p>Comprehensive debugging, visualization, and monitoring tools built right in.</p> </li> <li> <p>\u26a1 High Performance</p> <p>Optimized for production workloads with comprehensive benchmarking and Go's native concurrency.</p> </li> <li> <p>\ud83d\udd12 Type Safety</p> <p>Full Go type safety with comprehensive error handling. Catch issues at compile time.</p> </li> <li> <p>\ud83d\udc33 Production Ready</p> <p>Docker support, CI/CD pipelines, monitoring, and everything you need for production.</p> </li> </ul>"},{"location":"#quick-example","title":"\ud83c\udfc3 Quick Example","text":"<pre><code>package main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"log\"\n\n    \"github.com/piotrlaczkowski/GoLangGraph/pkg/builder\"\n    \"github.com/piotrlaczkowski/GoLangGraph/pkg/llm\"\n)\n\nfunc main() {\n    // \ud83e\udd16 Create a simple chat agent\n    agent := builder.OneLineChat(\"MyAgent\")\n\n    // \ud83c\udf10 Configure with OpenAI\n    provider, err := llm.NewOpenAIProvider(llm.OpenAIConfig{\n        APIKey: \"your-api-key\",\n        Model:  \"gpt-4\",\n    })\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    agent.SetLLMProvider(provider)\n\n    // \ud83d\ude80 Execute the agent\n    ctx := context.Background()\n    response, err := agent.Execute(ctx, \"Hello, world! \ud83d\udc4b\")\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    fmt.Printf(\"\ud83e\udd16 Agent Response: %s\\n\", response.Content)\n}\n</code></pre>"},{"location":"#architecture-overview","title":"\ud83c\udfd7\ufe0f Architecture Overview","text":"<pre><code>graph TB\n    A[\ud83d\udc64 User Input] --&gt; B[\ud83e\udd16 Agent]\n    B --&gt; C[\ud83d\udcca Graph Execution]\n    C --&gt; D[\ud83d\udd04 Node Processing]\n    D --&gt; E[\ud83c\udf10 LLM Provider]\n    D --&gt; F[\ud83d\udd27 Tools]\n    D --&gt; G[\ud83d\udcbe State Management]\n    G --&gt; H[\ud83d\uddc4\ufe0f Persistence Layer]\n    H --&gt; I[\ud83d\udcca Database]\n    E --&gt; J[\u2728 Response]\n    F --&gt; J\n    J --&gt; K[\ud83d\udc64 User Output]\n\n    style A fill:#e1f5fe\n    style K fill:#e8f5e8\n    style B fill:#fff3e0\n    style C fill:#f3e5f5\n    style G fill:#fce4ec</code></pre>"},{"location":"#use-cases","title":"\ud83c\udfaf Use Cases","text":"<ul> <li> <p>\ud83e\udd16 AI Agents</p> <p>Build intelligent agents that can reason, plan, and execute complex tasks using various LLM providers.</p> </li> <li> <p>\ud83d\udd0d RAG Applications</p> <p>Create sophisticated Retrieval-Augmented Generation systems with vector database integration.</p> </li> <li> <p>\ud83e\udd1d Multi-Agent Systems</p> <p>Design workflows where multiple specialized agents collaborate to solve complex problems.</p> </li> <li> <p>\ud83d\udcca Data Processing Pipelines</p> <p>Build intelligent data processing workflows that can adapt and make decisions based on content.</p> </li> <li> <p>\ud83d\udee0\ufe0f Automation Workflows</p> <p>Create smart automation systems that can handle exceptions and make intelligent decisions.</p> </li> <li> <p>\ud83c\udf10 API Orchestration</p> <p>Coordinate complex API interactions with intelligent error handling and retry logic.</p> </li> </ul>"},{"location":"#community-support","title":"\ud83c\udf1f Community &amp; Support","text":"<ul> <li> <p> \u2b50 GitHub</p> <p>Star the project, report issues, and contribute to the codebase. Join our growing community!</p> <p> GitHub Repository</p> </li> <li> <p> \ud83d\udcac Discord</p> <p>Join our community for real-time discussions, support, and collaboration with other developers.</p> <p> Join Discord</p> </li> <li> <p> \ud83d\udcda Documentation</p> <p>Comprehensive guides, examples, and API reference to help you build amazing AI workflows.</p> <p> Browse Docs</p> </li> <li> <p> \ud83d\udc1b Issues</p> <p>Report bugs, request features, and get help from the community. We're here to help!</p> <p> Report Issue</p> </li> </ul>"},{"location":"#why-choose-golanggraph","title":"\ud83d\ude80 Why Choose GoLangGraph?","text":"<ul> <li> <p>\u26a1 Performance First</p> <p>Built with Go's performance and concurrency in mind. Optimized for production workloads with comprehensive benchmarking.</p> </li> <li> <p>\ud83d\udc68\u200d\ud83d\udcbb Developer Experience</p> <p>Clean, intuitive API with excellent error handling and debugging tools. Comprehensive documentation and examples.</p> </li> <li> <p>\ud83c\udfed Production Ready</p> <p>Battle-tested with comprehensive test coverage, CI/CD pipelines, and production deployment guides.</p> </li> <li> <p>\ud83d\udd27 Extensible</p> <p>Plugin architecture allows easy extension with custom tools, LLM providers, and persistence backends.</p> </li> <li> <p>\ud83d\udd12 Secure</p> <p>Built-in security features including input validation, SQL injection prevention, and secure credential handling.</p> </li> <li> <p>\ud83c\udf0d Open Source</p> <p>MIT licensed with an active community. Contribute, customize, and build upon our foundation.</p> </li> </ul>"},{"location":"#performance-highlights","title":"\ud83d\udcca Performance Highlights","text":"<ul> <li> <p>\ud83c\udfc3 Fast Execution</p> <p>1.2ms average graph execution time 120ns state operations Concurrent node processing</p> </li> <li> <p>\ud83d\udcbe Memory Efficient</p> <p>512B per operation 8 allocs per execution Optimized state management</p> </li> <li> <p>\ud83d\udd17 Scalable</p> <p>Connection pooling Streaming execution Distributed processing ready</p> </li> <li> <p>\ud83d\udcc8 Benchmarked</p> <p>Comprehensive performance testing Production-validated metrics Continuous optimization</p> </li> </ul>"},{"location":"#roadmap","title":"\ud83d\uddfa\ufe0f Roadmap\ud83d\ude80 Ready to Build Your First AI Agent?","text":"<ul> <li> <p>\ud83d\ude80 v1.1 - Enhanced RAG</p> <ul> <li>\ud83d\udd0d Advanced vector search</li> <li>\ud83d\udcca Multi-modal embeddings</li> <li>\ud83e\udde0 Improved retrieval strategies</li> </ul> </li> <li> <p>\ud83c\udfad v1.2 - Multi-Modal</p> <ul> <li>\ud83d\uddbc\ufe0f Image processing</li> <li>\ud83c\udfb5 Audio support</li> <li>\ud83d\udcf9 Video analysis</li> </ul> </li> <li> <p>\ud83c\udf10 v1.3 - Distributed</p> <ul> <li>\u2601\ufe0f Cloud deployment</li> <li>\ud83d\udd04 Horizontal scaling</li> <li>\ud83c\udf0d Multi-region support</li> </ul> </li> <li> <p>\ud83c\udfa8 v1.4 - Visual Editor</p> <ul> <li>\ud83d\udda5\ufe0f Web-based editor</li> <li>\ud83d\udcca Real-time visualization</li> <li>\ud83c\udfaf Drag-and-drop workflows</li> </ul> </li> </ul> <p>Get started with GoLangGraph today and join the future of AI workflow development!</p>    [Get Started Now!](getting-started/quick-start.md){ .md-button .md-button--primary }    [View Examples](examples/ollama-integration.md){ .md-button }   [Join Community](https://discord.gg/golanggraph){ .md-button }  <p>\ud83c\udf1f Built with \u2764\ufe0f by the GoLangGraph Team</p> <p> \u2b50 Star us on GitHub \u2022     \ud83d\udc1b Report Bug \u2022     \ud83d\udcac Request Feature </p>"},{"location":"CORE_PACKAGE/","title":"Core Package Documentation","text":"<p>The <code>pkg/core</code> package provides the foundational components for GoLangGraph, including the graph execution engine and state management system.</p>"},{"location":"CORE_PACKAGE/#overview","title":"Overview","text":"<p>The core package implements a directed graph execution model where: - Nodes represent computational units (functions) - Edges define execution flow between nodes - State carries data throughout the execution - Conditions enable dynamic routing decisions</p>"},{"location":"CORE_PACKAGE/#key-components","title":"Key Components","text":""},{"location":"CORE_PACKAGE/#graph","title":"Graph","text":"<p>The <code>Graph</code> struct is the main execution engine that manages workflow execution.</p> <pre><code>type Graph struct {\n    ID        string\n    Name      string\n    Nodes     map[string]*Node\n    Edges     map[string]*Edge\n    StartNode string\n    EndNodes  []string\n    Config    *GraphConfig\n    // ... internal fields\n}\n</code></pre>"},{"location":"CORE_PACKAGE/#creating-a-graph","title":"Creating a Graph","text":"<pre><code>// Create a new graph\ngraph := core.NewGraph(\"my_workflow\")\n\n// Configure the graph\ngraph.Config.MaxIterations = 50\ngraph.Config.Timeout = 5 * time.Minute\ngraph.Config.EnableStreaming = true\n</code></pre>"},{"location":"CORE_PACKAGE/#adding-nodes","title":"Adding Nodes","text":"<pre><code>// Define a node function\nnodeFunc := func(ctx context.Context, state *core.BaseState) (*core.BaseState, error) {\n    // Process the state\n    state.Set(\"processed\", true)\n    return state, nil\n}\n\n// Add the node to the graph\ngraph.AddNode(\"process_node\", \"Process Data\", nodeFunc)\n</code></pre>"},{"location":"CORE_PACKAGE/#adding-edges","title":"Adding Edges","text":"<pre><code>// Simple edge (unconditional)\ngraph.AddEdge(\"node1\", \"node2\", nil)\n\n// Conditional edge\ncondition := func(ctx context.Context, state *core.BaseState) (string, error) {\n    value, _ := state.Get(\"decision\")\n    if value == \"continue\" {\n        return \"node2\", nil\n    }\n    return \"\", nil // Don't take this edge\n}\ngraph.AddEdge(\"node1\", \"node2\", condition)\n</code></pre>"},{"location":"CORE_PACKAGE/#executing-the-graph","title":"Executing the Graph","text":"<pre><code>// Set start and end nodes\ngraph.SetStartNode(\"start_node\")\ngraph.AddEndNode(\"end_node\")\n\n// Execute the workflow\ninitialState := core.NewBaseState()\ninitialState.Set(\"input\", \"Hello, World!\")\n\nresult, err := graph.Execute(context.Background(), initialState)\nif err != nil {\n    log.Fatal(err)\n}\n\n// Access the final state\noutput, _ := result.Get(\"output\")\nfmt.Printf(\"Result: %s\\n\", output)\n</code></pre>"},{"location":"CORE_PACKAGE/#state-management","title":"State Management","text":"<p>The <code>BaseState</code> struct provides thread-safe state management with history tracking.</p> <pre><code>type BaseState struct {\n    data     map[string]interface{}\n    metadata map[string]interface{}\n    history  []StateSnapshot\n    mu       sync.RWMutex\n}\n</code></pre>"},{"location":"CORE_PACKAGE/#state-operations","title":"State Operations","text":"<pre><code>// Create a new state\nstate := core.NewBaseState()\n\n// Set values\nstate.Set(\"key\", \"value\")\nstate.Set(\"number\", 42)\nstate.Set(\"data\", map[string]interface{}{\n    \"nested\": \"value\",\n})\n\n// Get values\nvalue, exists := state.Get(\"key\")\nif exists {\n    fmt.Printf(\"Value: %s\\n\", value)\n}\n\n// Delete values\nstate.Delete(\"key\")\n\n// Get all keys\nkeys := state.Keys()\n\n// Clone state (deep copy)\ncloned := state.Clone()\n\n// Merge states\nother := core.NewBaseState()\nother.Set(\"new_key\", \"new_value\")\nstate.Merge(other)\n</code></pre>"},{"location":"CORE_PACKAGE/#state-metadata","title":"State Metadata","text":"<pre><code>// Set metadata\nstate.SetMetadata(\"version\", \"1.0\")\nstate.SetMetadata(\"timestamp\", time.Now())\n\n// Get metadata\nversion, _ := state.GetMetadata(\"version\")\n\n// Get all metadata\nmetadata := state.GetAllMetadata()\n</code></pre>"},{"location":"CORE_PACKAGE/#state-history","title":"State History","text":"<pre><code>// Create a snapshot\nsnapshot := state.CreateSnapshot(\"checkpoint_1\")\n\n// Restore from snapshot\nerr := state.RestoreFromSnapshot(snapshot)\nif err != nil {\n    log.Printf(\"Failed to restore: %v\", err)\n}\n\n// Get history\nhistory := state.GetHistory()\nfor _, snapshot := range history {\n    fmt.Printf(\"Snapshot: %s at %v\\n\", snapshot.Name, snapshot.Timestamp)\n}\n</code></pre>"},{"location":"CORE_PACKAGE/#node-functions","title":"Node Functions","text":"<p>Node functions are the building blocks of your workflow. They receive a context and state, and return a modified state.</p> <pre><code>type NodeFunc func(ctx context.Context, state *BaseState) (*BaseState, error)\n</code></pre>"},{"location":"CORE_PACKAGE/#simple-node","title":"Simple Node","text":"<pre><code>simpleNode := func(ctx context.Context, state *BaseState) (*BaseState, error) {\n    // Get input\n    input, _ := state.Get(\"input\")\n\n    // Process\n    result := strings.ToUpper(input.(string))\n\n    // Set output\n    state.Set(\"output\", result)\n\n    return state, nil\n}\n</code></pre>"},{"location":"CORE_PACKAGE/#node-with-error-handling","title":"Node with Error Handling","text":"<pre><code>validationNode := func(ctx context.Context, state *BaseState) (*BaseState, error) {\n    input, exists := state.Get(\"input\")\n    if !exists {\n        return nil, fmt.Errorf(\"input is required\")\n    }\n\n    if input == \"\" {\n        return nil, fmt.Errorf(\"input cannot be empty\")\n    }\n\n    state.Set(\"validated\", true)\n    return state, nil\n}\n</code></pre>"},{"location":"CORE_PACKAGE/#async-node","title":"Async Node","text":"<pre><code>asyncNode := func(ctx context.Context, state *BaseState) (*BaseState, error) {\n    // Check for cancellation\n    select {\n    case &lt;-ctx.Done():\n        return nil, ctx.Err()\n    default:\n    }\n\n    // Simulate async work\n    time.Sleep(100 * time.Millisecond)\n\n    state.Set(\"async_result\", \"completed\")\n    return state, nil\n}\n</code></pre>"},{"location":"CORE_PACKAGE/#edge-conditions","title":"Edge Conditions","text":"<p>Edge conditions enable dynamic routing based on state values.</p> <pre><code>type EdgeCondition func(ctx context.Context, state *BaseState) (string, error)\n</code></pre>"},{"location":"CORE_PACKAGE/#simple-condition","title":"Simple Condition","text":"<pre><code>condition := func(ctx context.Context, state *BaseState) (string, error) {\n    value, _ := state.Get(\"decision\")\n    if value == \"yes\" {\n        return \"yes_node\", nil\n    }\n    return \"no_node\", nil\n}\n</code></pre>"},{"location":"CORE_PACKAGE/#complex-condition","title":"Complex Condition","text":"<pre><code>complexCondition := func(ctx context.Context, state *BaseState) (string, error) {\n    score, exists := state.Get(\"score\")\n    if !exists {\n        return \"\", fmt.Errorf(\"score is required for routing\")\n    }\n\n    scoreValue := score.(float64)\n    switch {\n    case scoreValue &gt;= 90:\n        return \"excellent_node\", nil\n    case scoreValue &gt;= 70:\n        return \"good_node\", nil\n    case scoreValue &gt;= 50:\n        return \"average_node\", nil\n    default:\n        return \"poor_node\", nil\n    }\n}\n</code></pre>"},{"location":"CORE_PACKAGE/#graph-configuration","title":"Graph Configuration","text":"<p>The <code>GraphConfig</code> struct provides configuration options for graph execution.</p> <pre><code>type GraphConfig struct {\n    MaxIterations     int           // Maximum number of iterations\n    Timeout           time.Duration // Execution timeout\n    EnableStreaming   bool          // Enable real-time streaming\n    EnableCheckpoints bool          // Enable checkpointing\n    ParallelExecution bool          // Enable parallel execution\n    RetryAttempts     int           // Number of retry attempts\n    RetryDelay        time.Duration // Delay between retries\n}\n</code></pre>"},{"location":"CORE_PACKAGE/#custom-configuration","title":"Custom Configuration","text":"<pre><code>config := &amp;core.GraphConfig{\n    MaxIterations:     100,\n    Timeout:           10 * time.Minute,\n    EnableStreaming:   true,\n    EnableCheckpoints: true,\n    ParallelExecution: true,\n    RetryAttempts:     3,\n    RetryDelay:        1 * time.Second,\n}\n\ngraph := core.NewGraph(\"configured_graph\")\ngraph.Config = config\n</code></pre>"},{"location":"CORE_PACKAGE/#streaming-execution","title":"Streaming Execution","text":"<p>Enable real-time monitoring of graph execution.</p> <pre><code>// Enable streaming\ngraph.Config.EnableStreaming = true\n\n// Get the streaming channel\nstreamChan := graph.Stream()\n\n// Execute in a goroutine\ngo func() {\n    result, err := graph.Execute(context.Background(), initialState)\n    if err != nil {\n        log.Printf(\"Execution failed: %v\", err)\n    }\n}()\n\n// Listen for execution updates\nfor result := range streamChan {\n    fmt.Printf(\"Node %s completed in %v\\n\", result.NodeID, result.Duration)\n    if result.Error != nil {\n        fmt.Printf(\"Error in node %s: %v\\n\", result.NodeID, result.Error)\n    }\n}\n</code></pre>"},{"location":"CORE_PACKAGE/#parallel-execution","title":"Parallel Execution","text":"<p>Execute multiple nodes in parallel for improved performance.</p> <pre><code>// Enable parallel execution\ngraph.Config.ParallelExecution = true\n\n// Execute multiple nodes in parallel\nnodeIDs := []string{\"node1\", \"node2\", \"node3\"}\nresults, err := graph.ExecuteParallel(context.Background(), nodeIDs, state)\nif err != nil {\n    log.Fatal(err)\n}\n\n// Process results\nfor nodeID, result := range results {\n    fmt.Printf(\"Node %s: Success=%v, Duration=%v\\n\", \n        nodeID, result.Success, result.Duration)\n}\n</code></pre>"},{"location":"CORE_PACKAGE/#graph-introspection","title":"Graph Introspection","text":"<p>Get information about the graph structure and execution.</p> <pre><code>// Get topology\ntopology := graph.GetTopology()\nfor from, targets := range topology {\n    fmt.Printf(\"Node %s connects to: %v\\n\", from, targets)\n}\n\n// Get execution history\nhistory := graph.GetExecutionHistory()\nfor _, result := range history {\n    fmt.Printf(\"Executed %s at %v (Duration: %v)\\n\", \n        result.NodeID, result.Timestamp, result.Duration)\n}\n\n// Get current state\ncurrentState := graph.GetCurrentState()\nif currentState != nil {\n    fmt.Printf(\"Current state has %d keys\\n\", len(currentState.Keys()))\n}\n\n// Check if running\nif graph.IsRunning() {\n    fmt.Println(\"Graph is currently executing\")\n}\n</code></pre>"},{"location":"CORE_PACKAGE/#error-handling","title":"Error Handling","text":"<p>Comprehensive error handling throughout the execution lifecycle.</p> <pre><code>// Node with error handling\nerrorNode := func(ctx context.Context, state *BaseState) (*BaseState, error) {\n    defer func() {\n        if r := recover(); r != nil {\n            log.Printf(\"Recovered from panic: %v\", r)\n        }\n    }()\n\n    // Validate inputs\n    if err := validateInputs(state); err != nil {\n        return nil, fmt.Errorf(\"validation failed: %w\", err)\n    }\n\n    // Process with error handling\n    result, err := processData(state)\n    if err != nil {\n        return nil, fmt.Errorf(\"processing failed: %w\", err)\n    }\n\n    state.Set(\"result\", result)\n    return state, nil\n}\n\n// Execute with error handling\nresult, err := graph.Execute(context.Background(), initialState)\nif err != nil {\n    switch {\n    case errors.Is(err, context.DeadlineExceeded):\n        log.Printf(\"Execution timed out\")\n    case errors.Is(err, context.Canceled):\n        log.Printf(\"Execution was canceled\")\n    default:\n        log.Printf(\"Execution failed: %v\", err)\n    }\n    return\n}\n</code></pre>"},{"location":"CORE_PACKAGE/#best-practices","title":"Best Practices","text":""},{"location":"CORE_PACKAGE/#1-state-management","title":"1. State Management","text":"<pre><code>// \u2705 Good: Use typed access with validation\nfunc safeGetString(state *core.BaseState, key string) (string, error) {\n    value, exists := state.Get(key)\n    if !exists {\n        return \"\", fmt.Errorf(\"key %s not found\", key)\n    }\n\n    str, ok := value.(string)\n    if !ok {\n        return \"\", fmt.Errorf(\"key %s is not a string\", key)\n    }\n\n    return str, nil\n}\n\n// \u274c Bad: Direct type assertion without checking\nfunc unsafeGetString(state *core.BaseState, key string) string {\n    value, _ := state.Get(key)\n    return value.(string) // Panic if not string or doesn't exist\n}\n</code></pre>"},{"location":"CORE_PACKAGE/#2-node-design","title":"2. Node Design","text":"<pre><code>// \u2705 Good: Focused, single-responsibility nodes\nfunc validateInputNode(ctx context.Context, state *core.BaseState) (*core.BaseState, error) {\n    // Only validate inputs\n    return validateInputs(state)\n}\n\nfunc processDataNode(ctx context.Context, state *core.BaseState) (*core.BaseState, error) {\n    // Only process data\n    return processData(state)\n}\n\n// \u274c Bad: Monolithic node doing everything\nfunc monolithicNode(ctx context.Context, state *core.BaseState) (*core.BaseState, error) {\n    // Validate, process, format, save - too many responsibilities\n    // ...\n}\n</code></pre>"},{"location":"CORE_PACKAGE/#3-error-handling","title":"3. Error Handling","text":"<pre><code>// \u2705 Good: Descriptive error messages with context\nfunc processNode(ctx context.Context, state *core.BaseState) (*core.BaseState, error) {\n    input, exists := state.Get(\"input\")\n    if !exists {\n        return nil, fmt.Errorf(\"processNode: input is required\")\n    }\n\n    result, err := processInput(input)\n    if err != nil {\n        return nil, fmt.Errorf(\"processNode: failed to process input %v: %w\", input, err)\n    }\n\n    state.Set(\"result\", result)\n    return state, nil\n}\n</code></pre>"},{"location":"CORE_PACKAGE/#4-context-usage","title":"4. Context Usage","text":"<pre><code>// \u2705 Good: Respect context cancellation\nfunc longRunningNode(ctx context.Context, state *core.BaseState) (*core.BaseState, error) {\n    for i := 0; i &lt; 1000; i++ {\n        select {\n        case &lt;-ctx.Done():\n            return nil, ctx.Err()\n        default:\n        }\n\n        // Do work\n        time.Sleep(10 * time.Millisecond)\n    }\n\n    return state, nil\n}\n</code></pre>"},{"location":"CORE_PACKAGE/#testing","title":"Testing","text":"<p>The core package includes comprehensive tests. Run them with:</p> <pre><code>go test ./pkg/core -v\n</code></pre>"},{"location":"CORE_PACKAGE/#example-test","title":"Example Test","text":"<pre><code>func TestGraph_Execute(t *testing.T) {\n    graph := core.NewGraph(\"test_graph\")\n\n    node1 := func(ctx context.Context, state *core.BaseState) (*core.BaseState, error) {\n        state.Set(\"node1_executed\", true)\n        return state, nil\n    }\n\n    node2 := func(ctx context.Context, state *core.BaseState) (*core.BaseState, error) {\n        state.Set(\"node2_executed\", true)\n        return state, nil\n    }\n\n    graph.AddNode(\"node1\", \"Node 1\", node1)\n    graph.AddNode(\"node2\", \"Node 2\", node2)\n    graph.AddEdge(\"node1\", \"node2\", nil)\n    graph.SetStartNode(\"node1\")\n    graph.AddEndNode(\"node2\")\n\n    state := core.NewBaseState()\n    result, err := graph.Execute(context.Background(), state)\n\n    assert.NoError(t, err)\n    assert.NotNil(t, result)\n\n    val1, _ := result.Get(\"node1_executed\")\n    val2, _ := result.Get(\"node2_executed\")\n    assert.True(t, val1.(bool))\n    assert.True(t, val2.(bool))\n}\n</code></pre>"},{"location":"CORE_PACKAGE/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>State Cloning: State is cloned at each node execution. For large states, consider using references where appropriate.</li> <li>Concurrent Access: All state operations are thread-safe, but excessive concurrent access may impact performance.</li> <li>Memory Usage: Large execution histories can consume significant memory. Consider periodic cleanup.</li> <li>Streaming: Streaming adds minimal overhead but requires proper channel management.</li> </ul>"},{"location":"CORE_PACKAGE/#conclusion","title":"Conclusion","text":"<p>The core package provides a solid foundation for building complex workflow systems. Its graph-based execution model, combined with flexible state management and comprehensive error handling, makes it suitable for a wide range of applications from simple data processing pipelines to complex AI agent workflows. </p>"},{"location":"PERSISTENCE_GUIDE/","title":"Persistence Package Documentation","text":"<p>The <code>pkg/persistence</code> package provides comprehensive database integration and state persistence capabilities for GoLangGraph, including support for traditional databases, vector databases, and checkpointing systems.</p>"},{"location":"PERSISTENCE_GUIDE/#overview","title":"Overview","text":"<p>The persistence package enables: - Database Connections: Support for PostgreSQL, Redis, and vector databases - State Checkpointing: Save and restore workflow states - Vector Storage: RAG (Retrieval-Augmented Generation) capabilities - Document Management: Store and search documents with embeddings - Session Management: Thread-safe session and conversation handling</p>"},{"location":"PERSISTENCE_GUIDE/#supported-databases","title":"Supported Databases","text":""},{"location":"PERSISTENCE_GUIDE/#postgresql","title":"PostgreSQL","text":"<p>Full-featured relational database support with advanced features: - JSON/JSONB support for flexible data storage - Connection pooling and transaction management - Schema migrations and versioning - Full-text search capabilities</p>"},{"location":"PERSISTENCE_GUIDE/#redis","title":"Redis","text":"<p>High-performance in-memory data store: - Key-value storage with expiration - Pub/Sub messaging for real-time updates - Caching layer for improved performance - Session storage and management</p>"},{"location":"PERSISTENCE_GUIDE/#pgvector","title":"pgvector","text":"<p>Vector database capabilities for AI applications: - High-dimensional vector storage - Similarity search with multiple distance metrics - Embedding storage and retrieval - RAG (Retrieval-Augmented Generation) support</p>"},{"location":"PERSISTENCE_GUIDE/#database-configuration","title":"Database Configuration","text":""},{"location":"PERSISTENCE_GUIDE/#postgresql-configuration","title":"PostgreSQL Configuration","text":"<pre><code>import \"github.com/piotrlaczkowski/GoLangGraph/pkg/persistence\"\n\n// Basic PostgreSQL configuration\npgConfig := persistence.PostgreSQLConfig{\n    Host:     \"localhost\",\n    Port:     5432,\n    Database: \"golanggraph\",\n    Username: \"user\",\n    Password: \"password\",\n    SSLMode:  \"disable\",\n}\n\n// Advanced configuration with connection pooling\npgConfig = persistence.PostgreSQLConfig{\n    Host:            \"localhost\",\n    Port:            5432,\n    Database:        \"golanggraph\",\n    Username:        \"user\",\n    Password:        \"password\",\n    SSLMode:         \"require\",\n    MaxConnections:  25,\n    MaxIdleConns:    5,\n    ConnMaxLifetime: 30 * time.Minute,\n    ConnMaxIdleTime: 5 * time.Minute,\n}\n\n// Validate configuration\nif err := pgConfig.Validate(); err != nil {\n    log.Fatal(\"Invalid PostgreSQL config:\", err)\n}\n</code></pre>"},{"location":"PERSISTENCE_GUIDE/#redis-configuration","title":"Redis Configuration","text":"<pre><code>// Basic Redis configuration\nredisConfig := persistence.RedisConfig{\n    Host:     \"localhost\",\n    Port:     6379,\n    Password: \"\",\n    Database: 0,\n}\n\n// Advanced configuration with clustering\nredisConfig = persistence.RedisConfig{\n    Host:           \"localhost\",\n    Port:           6379,\n    Password:       \"secure_password\",\n    Database:       0,\n    PoolSize:       10,\n    MinIdleConns:   3,\n    MaxRetries:     3,\n    DialTimeout:    5 * time.Second,\n    ReadTimeout:    3 * time.Second,\n    WriteTimeout:   3 * time.Second,\n    PoolTimeout:    4 * time.Second,\n    IdleTimeout:    5 * time.Minute,\n}\n\n// Validate configuration\nif err := redisConfig.Validate(); err != nil {\n    log.Fatal(\"Invalid Redis config:\", err)\n}\n</code></pre>"},{"location":"PERSISTENCE_GUIDE/#pgvector-configuration","title":"pgvector Configuration","text":"<pre><code>// pgvector configuration for RAG applications\npgvectorConfig := persistence.PgVectorConfig{\n    Host:       \"localhost\",\n    Port:       5432,\n    Database:   \"vectordb\",\n    Username:   \"vector_user\",\n    Password:   \"vector_password\",\n    SSLMode:    \"disable\",\n    Dimensions: 1536, // OpenAI embedding dimensions\n\n    // Vector-specific settings\n    IndexType:    \"ivfflat\",\n    IndexOptions: map[string]interface{}{\n        \"lists\": 100,\n    },\n    DistanceMetric: \"cosine\",\n}\n\n// Validate configuration\nif err := pgvectorConfig.Validate(); err != nil {\n    log.Fatal(\"Invalid pgvector config:\", err)\n}\n</code></pre>"},{"location":"PERSISTENCE_GUIDE/#database-manager","title":"Database Manager","text":"<p>The <code>DatabaseManager</code> provides centralized database connection management:</p> <pre><code>// Create database manager\ndbManager := persistence.NewDatabaseManager()\n\n// Add database connections\nerr := dbManager.AddPostgreSQL(\"main\", pgConfig)\nif err != nil {\n    log.Fatal(\"Failed to add PostgreSQL:\", err)\n}\n\nerr = dbManager.AddRedis(\"cache\", redisConfig)\nif err != nil {\n    log.Fatal(\"Failed to add Redis:\", err)\n}\n\nerr = dbManager.AddPgVector(\"vectors\", pgvectorConfig)\nif err != nil {\n    log.Fatal(\"Failed to add pgvector:\", err)\n}\n\n// Get connections\npgConn, err := dbManager.GetPostgreSQL(\"main\")\nif err != nil {\n    log.Fatal(\"Failed to get PostgreSQL connection:\", err)\n}\n\nredisConn, err := dbManager.GetRedis(\"cache\")\nif err != nil {\n    log.Fatal(\"Failed to get Redis connection:\", err)\n}\n\nvectorConn, err := dbManager.GetPgVector(\"vectors\")\nif err != nil {\n    log.Fatal(\"Failed to get pgvector connection:\", err)\n}\n\n// Health checks\nhealthStatus := dbManager.HealthCheck()\nfor name, healthy := range healthStatus {\n    if healthy {\n        fmt.Printf(\"Database %s: healthy\\n\", name)\n    } else {\n        fmt.Printf(\"Database %s: unhealthy\\n\", name)\n    }\n}\n\n// Close all connections\ndefer dbManager.Close()\n</code></pre>"},{"location":"PERSISTENCE_GUIDE/#checkpointing-system","title":"Checkpointing System","text":"<p>The checkpointing system allows you to save and restore workflow states:</p>"},{"location":"PERSISTENCE_GUIDE/#database-checkpointer","title":"Database Checkpointer","text":"<pre><code>// Create database checkpointer\ncheckpointer, err := persistence.NewDatabaseCheckpointer(dbManager, \"main\")\nif err != nil {\n    log.Fatal(\"Failed to create checkpointer:\", err)\n}\n\n// Save a checkpoint\ncheckpoint := &amp;persistence.Checkpoint{\n    ThreadID:    \"conversation-123\",\n    State:       state,\n    Metadata:    map[string]interface{}{\n        \"user_id\":    \"user123\",\n        \"session_id\": \"session456\",\n        \"step\":       \"processing\",\n    },\n    Timestamp:   time.Now(),\n    Version:     1,\n}\n\nerr = checkpointer.SaveCheckpoint(checkpoint)\nif err != nil {\n    log.Fatal(\"Failed to save checkpoint:\", err)\n}\n\n// Load a checkpoint\nloadedCheckpoint, err := checkpointer.LoadCheckpoint(\"conversation-123\")\nif err != nil {\n    log.Fatal(\"Failed to load checkpoint:\", err)\n}\n\n// List checkpoints for a thread\ncheckpoints, err := checkpointer.ListCheckpoints(\"conversation-123\")\nif err != nil {\n    log.Fatal(\"Failed to list checkpoints:\", err)\n}\n\n// Delete old checkpoints\nerr = checkpointer.DeleteCheckpoint(\"conversation-123\", 1)\nif err != nil {\n    log.Fatal(\"Failed to delete checkpoint:\", err)\n}\n</code></pre>"},{"location":"PERSISTENCE_GUIDE/#memory-checkpointer","title":"Memory Checkpointer","text":"<pre><code>// Create in-memory checkpointer (for testing/development)\nmemCheckpointer := persistence.NewMemoryCheckpointer()\n\n// Use the same interface as database checkpointer\nerr = memCheckpointer.SaveCheckpoint(checkpoint)\nif err != nil {\n    log.Fatal(\"Failed to save checkpoint:\", err)\n}\n\nloadedCheckpoint, err := memCheckpointer.LoadCheckpoint(\"conversation-123\")\nif err != nil {\n    log.Fatal(\"Failed to load checkpoint:\", err)\n}\n</code></pre>"},{"location":"PERSISTENCE_GUIDE/#vector-database-rag-support","title":"Vector Database &amp; RAG Support","text":""},{"location":"PERSISTENCE_GUIDE/#document-storage","title":"Document Storage","text":"<pre><code>// Create vector store\nvectorStore, err := persistence.NewPgVectorStore(pgvectorConfig)\nif err != nil {\n    log.Fatal(\"Failed to create vector store:\", err)\n}\n\n// Define documents\ndocuments := []persistence.Document{\n    {\n        ID:      \"doc1\",\n        Content: \"GoLangGraph is a powerful framework for building AI agent workflows.\",\n        Metadata: map[string]interface{}{\n            \"source\":    \"documentation\",\n            \"category\":  \"framework\",\n            \"timestamp\": time.Now(),\n        },\n        Embedding: []float32{0.1, 0.2, 0.3, /* ... 1536 dimensions */},\n    },\n    {\n        ID:      \"doc2\",\n        Content: \"The persistence package provides database integration capabilities.\",\n        Metadata: map[string]interface{}{\n            \"source\":    \"documentation\",\n            \"category\":  \"persistence\",\n            \"timestamp\": time.Now(),\n        },\n        Embedding: []float32{0.2, 0.3, 0.4, /* ... 1536 dimensions */},\n    },\n}\n\n// Store documents\nerr = vectorStore.StoreDocuments(documents)\nif err != nil {\n    log.Fatal(\"Failed to store documents:\", err)\n}\n\n// Update a document\nupdatedDoc := persistence.Document{\n    ID:      \"doc1\",\n    Content: \"GoLangGraph is an advanced framework for building AI agent workflows with persistence.\",\n    Metadata: map[string]interface{}{\n        \"source\":    \"documentation\",\n        \"category\":  \"framework\",\n        \"updated\":   time.Now(),\n    },\n    Embedding: []float32{0.15, 0.25, 0.35, /* ... 1536 dimensions */},\n}\n\nerr = vectorStore.UpdateDocument(updatedDoc)\nif err != nil {\n    log.Fatal(\"Failed to update document:\", err)\n}\n</code></pre>"},{"location":"PERSISTENCE_GUIDE/#similarity-search","title":"Similarity Search","text":"<pre><code>// Search by embedding vector\nqueryEmbedding := []float32{0.1, 0.2, 0.3, /* ... 1536 dimensions */}\nresults, err := vectorStore.SimilaritySearchByVector(queryEmbedding, 5)\nif err != nil {\n    log.Fatal(\"Failed to search by vector:\", err)\n}\n\n// Search by text (requires embedding generation)\ntextResults, err := vectorStore.SimilaritySearch(\"AI agent workflows\", 5)\nif err != nil {\n    log.Fatal(\"Failed to search by text:\", err)\n}\n\n// Process results\nfor _, result := range results {\n    fmt.Printf(\"Document ID: %s\\n\", result.ID)\n    fmt.Printf(\"Content: %s\\n\", result.Content)\n    fmt.Printf(\"Similarity Score: %.4f\\n\", result.Score)\n    fmt.Printf(\"Metadata: %+v\\n\", result.Metadata)\n    fmt.Println(\"---\")\n}\n</code></pre>"},{"location":"PERSISTENCE_GUIDE/#advanced-search-with-filters","title":"Advanced Search with Filters","text":"<pre><code>// Search with metadata filters\nfilters := map[string]interface{}{\n    \"category\": \"framework\",\n    \"source\":   \"documentation\",\n}\n\nfilteredResults, err := vectorStore.SimilaritySearchWithFilters(\n    queryEmbedding, \n    5, \n    filters,\n)\nif err != nil {\n    log.Fatal(\"Failed to search with filters:\", err)\n}\n\n// Search with score threshold\nthresholdResults, err := vectorStore.SimilaritySearchWithThreshold(\n    queryEmbedding,\n    5,\n    0.8, // Minimum similarity score\n)\nif err != nil {\n    log.Fatal(\"Failed to search with threshold:\", err)\n}\n</code></pre>"},{"location":"PERSISTENCE_GUIDE/#session-and-thread-management","title":"Session and Thread Management","text":""},{"location":"PERSISTENCE_GUIDE/#session-management","title":"Session Management","text":"<pre><code>// Create session manager\nsessionManager := persistence.NewSessionManager(dbManager, \"main\")\n\n// Create a new session\nsession := &amp;persistence.Session{\n    ID:        \"session-123\",\n    UserID:    \"user-456\",\n    Metadata:  map[string]interface{}{\n        \"app_version\": \"1.0.0\",\n        \"user_agent\":  \"GoLangGraph-Client/1.0\",\n    },\n    CreatedAt: time.Now(),\n    UpdatedAt: time.Now(),\n}\n\nerr = sessionManager.CreateSession(session)\nif err != nil {\n    log.Fatal(\"Failed to create session:\", err)\n}\n\n// Get session\nretrievedSession, err := sessionManager.GetSession(\"session-123\")\nif err != nil {\n    log.Fatal(\"Failed to get session:\", err)\n}\n\n// Update session\nretrievedSession.Metadata[\"last_activity\"] = time.Now()\nerr = sessionManager.UpdateSession(retrievedSession)\nif err != nil {\n    log.Fatal(\"Failed to update session:\", err)\n}\n\n// List user sessions\nuserSessions, err := sessionManager.ListUserSessions(\"user-456\")\nif err != nil {\n    log.Fatal(\"Failed to list user sessions:\", err)\n}\n\n// Delete session\nerr = sessionManager.DeleteSession(\"session-123\")\nif err != nil {\n    log.Fatal(\"Failed to delete session:\", err)\n}\n</code></pre>"},{"location":"PERSISTENCE_GUIDE/#thread-management","title":"Thread Management","text":"<pre><code>// Create thread manager\nthreadManager := persistence.NewThreadManager(dbManager, \"main\")\n\n// Create a new thread\nthread := &amp;persistence.Thread{\n    ID:        \"thread-789\",\n    SessionID: \"session-123\",\n    UserID:    \"user-456\",\n    Title:     \"AI Workflow Discussion\",\n    Metadata:  map[string]interface{}{\n        \"topic\":    \"workflow_design\",\n        \"priority\": \"high\",\n    },\n    CreatedAt: time.Now(),\n    UpdatedAt: time.Now(),\n}\n\nerr = threadManager.CreateThread(thread)\nif err != nil {\n    log.Fatal(\"Failed to create thread:\", err)\n}\n\n// Get thread\nretrievedThread, err := threadManager.GetThread(\"thread-789\")\nif err != nil {\n    log.Fatal(\"Failed to get thread:\", err)\n}\n\n// List session threads\nsessionThreads, err := threadManager.ListSessionThreads(\"session-123\")\nif err != nil {\n    log.Fatal(\"Failed to list session threads:\", err)\n}\n\n// Update thread\nretrievedThread.Title = \"Updated AI Workflow Discussion\"\nerr = threadManager.UpdateThread(retrievedThread)\nif err != nil {\n    log.Fatal(\"Failed to update thread:\", err)\n}\n\n// Delete thread\nerr = threadManager.DeleteThread(\"thread-789\")\nif err != nil {\n    log.Fatal(\"Failed to delete thread:\", err)\n}\n</code></pre>"},{"location":"PERSISTENCE_GUIDE/#advanced-features","title":"Advanced Features","text":""},{"location":"PERSISTENCE_GUIDE/#connection-pooling","title":"Connection Pooling","text":"<pre><code>// Configure connection pooling for PostgreSQL\npgConfig := persistence.PostgreSQLConfig{\n    // ... basic config\n    MaxConnections:  25,              // Maximum number of connections\n    MaxIdleConns:    5,               // Maximum idle connections\n    ConnMaxLifetime: 30 * time.Minute, // Connection lifetime\n    ConnMaxIdleTime: 5 * time.Minute,  // Idle connection timeout\n}\n\n// Configure connection pooling for Redis\nredisConfig := persistence.RedisConfig{\n    // ... basic config\n    PoolSize:     10,               // Connection pool size\n    MinIdleConns: 3,                // Minimum idle connections\n    PoolTimeout:  4 * time.Second,  // Pool timeout\n    IdleTimeout:  5 * time.Minute,  // Idle connection timeout\n}\n</code></pre>"},{"location":"PERSISTENCE_GUIDE/#transaction-management","title":"Transaction Management","text":"<pre><code>// Begin transaction\ntx, err := pgConn.BeginTx(context.Background(), nil)\nif err != nil {\n    log.Fatal(\"Failed to begin transaction:\", err)\n}\ndefer tx.Rollback() // Rollback if not committed\n\n// Perform operations within transaction\n_, err = tx.ExecContext(context.Background(), \n    \"INSERT INTO checkpoints (thread_id, state_data) VALUES ($1, $2)\",\n    \"thread-123\", stateData)\nif err != nil {\n    log.Fatal(\"Failed to insert checkpoint:\", err)\n}\n\n_, err = tx.ExecContext(context.Background(),\n    \"UPDATE sessions SET updated_at = $1 WHERE id = $2\",\n    time.Now(), \"session-123\")\nif err != nil {\n    log.Fatal(\"Failed to update session:\", err)\n}\n\n// Commit transaction\nerr = tx.Commit()\nif err != nil {\n    log.Fatal(\"Failed to commit transaction:\", err)\n}\n</code></pre>"},{"location":"PERSISTENCE_GUIDE/#batch-operations","title":"Batch Operations","text":"<pre><code>// Batch insert documents\nbatchSize := 100\ndocuments := make([]persistence.Document, 1000)\n// ... populate documents\n\nfor i := 0; i &lt; len(documents); i += batchSize {\n    end := i + batchSize\n    if end &gt; len(documents) {\n        end = len(documents)\n    }\n\n    batch := documents[i:end]\n    err := vectorStore.StoreDocuments(batch)\n    if err != nil {\n        log.Printf(\"Failed to store batch %d-%d: %v\", i, end, err)\n        continue\n    }\n\n    fmt.Printf(\"Stored batch %d-%d\\n\", i, end)\n}\n</code></pre>"},{"location":"PERSISTENCE_GUIDE/#monitoring-and-metrics","title":"Monitoring and Metrics","text":"<pre><code>// Database health monitoring\ngo func() {\n    ticker := time.NewTicker(30 * time.Second)\n    defer ticker.Stop()\n\n    for {\n        select {\n        case &lt;-ticker.C:\n            health := dbManager.HealthCheck()\n            for name, healthy := range health {\n                if !healthy {\n                    log.Printf(\"Database %s is unhealthy\", name)\n                    // Trigger alerts or recovery procedures\n                }\n            }\n        }\n    }\n}()\n\n// Connection pool monitoring\nstats := pgConn.Stats()\nfmt.Printf(\"Open connections: %d\\n\", stats.OpenConnections)\nfmt.Printf(\"In use: %d\\n\", stats.InUse)\nfmt.Printf(\"Idle: %d\\n\", stats.Idle)\n</code></pre>"},{"location":"PERSISTENCE_GUIDE/#testing","title":"Testing","text":"<p>The persistence package includes comprehensive tests:</p> <pre><code># Run all persistence tests\ngo test ./pkg/persistence -v\n\n# Run specific test\ngo test ./pkg/persistence -v -run TestDatabaseManager\n\n# Run integration tests (requires running databases)\ngo test ./pkg/persistence -v -tags=integration\n</code></pre>"},{"location":"PERSISTENCE_GUIDE/#example-test","title":"Example Test","text":"<pre><code>func TestDatabaseCheckpointer(t *testing.T) {\n    // Setup test database\n    dbManager := setupTestDatabase(t)\n    defer dbManager.Close()\n\n    // Create checkpointer\n    checkpointer, err := persistence.NewDatabaseCheckpointer(dbManager, \"test\")\n    require.NoError(t, err)\n\n    // Create test checkpoint\n    state := core.NewBaseState()\n    state.Set(\"test_key\", \"test_value\")\n\n    checkpoint := &amp;persistence.Checkpoint{\n        ThreadID:  \"test-thread\",\n        State:     state,\n        Metadata:  map[string]interface{}{\"test\": true},\n        Timestamp: time.Now(),\n        Version:   1,\n    }\n\n    // Save checkpoint\n    err = checkpointer.SaveCheckpoint(checkpoint)\n    require.NoError(t, err)\n\n    // Load checkpoint\n    loaded, err := checkpointer.LoadCheckpoint(\"test-thread\")\n    require.NoError(t, err)\n    require.Equal(t, checkpoint.ThreadID, loaded.ThreadID)\n\n    // Verify state\n    value, exists := loaded.State.Get(\"test_key\")\n    require.True(t, exists)\n    require.Equal(t, \"test_value\", value)\n}\n</code></pre>"},{"location":"PERSISTENCE_GUIDE/#best-practices","title":"Best Practices","text":""},{"location":"PERSISTENCE_GUIDE/#1-connection-management","title":"1. Connection Management","text":"<pre><code>// \u2705 Good: Use connection pooling\ndbManager := persistence.NewDatabaseManager()\ndefer dbManager.Close() // Always close connections\n\n// \u274c Bad: Creating new connections for each operation\n// This leads to connection leaks and poor performance\n</code></pre>"},{"location":"PERSISTENCE_GUIDE/#2-error-handling","title":"2. Error Handling","text":"<pre><code>// \u2705 Good: Handle specific database errors\nerr := checkpointer.SaveCheckpoint(checkpoint)\nif err != nil {\n    var pgErr *pq.Error\n    if errors.As(err, &amp;pgErr) {\n        switch pgErr.Code {\n        case \"23505\": // Unique violation\n            return fmt.Errorf(\"checkpoint already exists: %w\", err)\n        case \"23503\": // Foreign key violation\n            return fmt.Errorf(\"invalid thread reference: %w\", err)\n        default:\n            return fmt.Errorf(\"database error: %w\", err)\n        }\n    }\n    return fmt.Errorf(\"failed to save checkpoint: %w\", err)\n}\n</code></pre>"},{"location":"PERSISTENCE_GUIDE/#3-resource-cleanup","title":"3. Resource Cleanup","text":"<pre><code>// \u2705 Good: Always clean up resources\nfunc processWithTransaction(db *sql.DB) error {\n    tx, err := db.Begin()\n    if err != nil {\n        return err\n    }\n    defer tx.Rollback() // Rollback if not committed\n\n    // ... perform operations\n\n    return tx.Commit()\n}\n</code></pre>"},{"location":"PERSISTENCE_GUIDE/#4-configuration-validation","title":"4. Configuration Validation","text":"<pre><code>// \u2705 Good: Validate configuration before use\nif err := config.Validate(); err != nil {\n    return fmt.Errorf(\"invalid configuration: %w\", err)\n}\n\n// \u274c Bad: Using configuration without validation\n// This can lead to runtime errors\n</code></pre>"},{"location":"PERSISTENCE_GUIDE/#performance-optimization","title":"Performance Optimization","text":""},{"location":"PERSISTENCE_GUIDE/#1-connection-pooling","title":"1. Connection Pooling","text":"<pre><code>// Optimize connection pool settings based on your workload\npgConfig := persistence.PostgreSQLConfig{\n    MaxConnections:  25,              // Based on database limits\n    MaxIdleConns:    5,               // Keep some connections ready\n    ConnMaxLifetime: 30 * time.Minute, // Prevent stale connections\n    ConnMaxIdleTime: 5 * time.Minute,  // Clean up idle connections\n}\n</code></pre>"},{"location":"PERSISTENCE_GUIDE/#2-batch-operations","title":"2. Batch Operations","text":"<pre><code>// Process documents in batches for better performance\nconst batchSize = 100\nfor i := 0; i &lt; len(documents); i += batchSize {\n    batch := documents[i:min(i+batchSize, len(documents))]\n    if err := vectorStore.StoreDocuments(batch); err != nil {\n        log.Printf(\"Batch failed: %v\", err)\n    }\n}\n</code></pre>"},{"location":"PERSISTENCE_GUIDE/#3-indexing","title":"3. Indexing","text":"<pre><code>// Create appropriate indexes for your queries\nqueries := []string{\n    \"CREATE INDEX IF NOT EXISTS idx_checkpoints_thread_id ON checkpoints(thread_id)\",\n    \"CREATE INDEX IF NOT EXISTS idx_sessions_user_id ON sessions(user_id)\",\n    \"CREATE INDEX IF NOT EXISTS idx_documents_metadata ON documents USING GIN(metadata)\",\n}\n\nfor _, query := range queries {\n    if _, err := db.Exec(query); err != nil {\n        log.Printf(\"Failed to create index: %v\", err)\n    }\n}\n</code></pre>"},{"location":"PERSISTENCE_GUIDE/#conclusion","title":"Conclusion","text":"<p>The persistence package provides a comprehensive solution for data storage and retrieval in GoLangGraph applications. With support for multiple database types, advanced features like vector search, and robust error handling, it enables building production-ready AI applications with reliable data persistence. </p>"},{"location":"examples/ollama-integration/","title":"Ollama Integration with GoLangGraph","text":"<p>This document provides comprehensive guidance for using GoLangGraph with Ollama and local language models, specifically demonstrating integration with Google's Gemma 3:1B model.</p>"},{"location":"examples/ollama-integration/#overview","title":"Overview","text":"<p>The Ollama integration allows you to run GoLangGraph agents locally using open-source language models without requiring API keys or cloud services. This is perfect for:</p> <ul> <li>Local Development: Test and develop agents without external dependencies</li> <li>Privacy-Focused Applications: Keep all data processing local</li> <li>Cost-Effective Solutions: No API costs for development and testing</li> <li>Offline Capabilities: Run agents without internet connectivity</li> <li>Educational Purposes: Learn AI agent concepts with accessible models</li> </ul>"},{"location":"examples/ollama-integration/#prerequisites","title":"Prerequisites","text":""},{"location":"examples/ollama-integration/#1-install-ollama","title":"1. Install Ollama","text":"<p>macOS/Linux: <pre><code>curl -fsSL https://ollama.ai/install.sh | sh\n</code></pre></p> <p>Windows: Download from ollama.ai/download</p> <p>Verify Installation: <pre><code>ollama --version\n</code></pre></p>"},{"location":"examples/ollama-integration/#2-pull-gemma-31b-model","title":"2. Pull Gemma 3:1B Model","text":"<pre><code># Pull the model (this may take a few minutes)\nollama pull gemma3:1b\n\n# Verify the model is available\nollama list\n</code></pre>"},{"location":"examples/ollama-integration/#3-start-ollama-service","title":"3. Start Ollama Service","text":"<pre><code># Start Ollama server\nollama serve\n\n# Test basic functionality\nollama run gemma3:1b \"Hello, world!\"\n</code></pre>"},{"location":"examples/ollama-integration/#quick-start","title":"Quick Start","text":""},{"location":"examples/ollama-integration/#using-make-commands","title":"Using Make Commands","text":"<p>The easiest way to test the Ollama integration:</p> <pre><code># Run the complete Ollama demo\nmake example-ollama\n\n# Run comprehensive integration tests\nmake test-ollama\n\n# Test only the Ollama setup (no demo execution)\nmake test-ollama-setup\n</code></pre>"},{"location":"examples/ollama-integration/#manual-execution","title":"Manual Execution","text":"<pre><code># Build the demo\ngo build -o bin/ollama-demo ./cmd/examples\n\n# Run the demo\n./bin/ollama-demo\n</code></pre>"},{"location":"examples/ollama-integration/#demo-features","title":"Demo Features","text":"<p>The Ollama demo (<code>examples/ollama_demo.go</code>) demonstrates six key capabilities:</p>"},{"location":"examples/ollama-integration/#1-basic-chat-agent","title":"1. Basic Chat Agent","text":"<pre><code>config := &amp;agent.AgentConfig{\n    Name:        \"demo-chat\",\n    Type:        agent.AgentTypeChat,\n    Provider:    \"ollama\",\n    Model:       \"gemma3:1b\",\n    Temperature: 0.1,\n    MaxTokens:   100,\n}\n\nchatAgent := agent.NewAgent(config, llmManager, toolRegistry)\nexecution, err := chatAgent.Execute(ctx, \"Hello! Please say 'Hello from Gemma 3:1B!'\")\n</code></pre>"},{"location":"examples/ollama-integration/#2-react-agent-with-tools","title":"2. ReAct Agent with Tools","text":"<pre><code>config := &amp;agent.AgentConfig{\n    Name:          \"demo-react\",\n    Type:          agent.AgentTypeReAct,\n    Provider:      \"ollama\",\n    Model:         \"gemma3:1b\",\n    Tools:         []string{\"calculator\"},\n    MaxIterations: 3,\n}\n\nreactAgent := agent.NewAgent(config, llmManager, toolRegistry)\nexecution, err := reactAgent.Execute(ctx, \"What is 25 + 17? Please calculate this.\")\n</code></pre>"},{"location":"examples/ollama-integration/#3-multi-agent-coordination","title":"3. Multi-Agent Coordination","text":"<pre><code>// Create researcher and writer agents\nresearcher := agent.NewAgent(researcherConfig, llmManager, toolRegistry)\nwriter := agent.NewAgent(writerConfig, llmManager, toolRegistry)\n\n// Coordinate sequential execution\ncoordinator := agent.NewMultiAgentCoordinator()\ncoordinator.AddAgent(\"researcher\", researcher)\ncoordinator.AddAgent(\"writer\", writer)\n\nresults, err := coordinator.ExecuteSequential(ctx, \n    []string{\"researcher\", \"writer\"}, \n    \"Research and summarize: What is machine learning?\")\n</code></pre>"},{"location":"examples/ollama-integration/#4-quick-builder-pattern","title":"4. Quick Builder Pattern","text":"<pre><code>quick := builder.Quick().WithConfig(&amp;builder.QuickConfig{\n    DefaultModel:   \"gemma3:1b\",\n    OllamaURL:      \"http://localhost:11434\",\n    Temperature:    0.1,\n    MaxTokens:      100,\n    EnableAllTools: true,\n})\n\nchatAgent := quick.Chat(\"quick-demo\")\nexecution, err := chatAgent.Execute(ctx, \"Say 'Quick builder works!'\")\n</code></pre>"},{"location":"examples/ollama-integration/#5-custom-graph-execution","title":"5. Custom Graph Execution","text":"<pre><code>graph := core.NewGraph(\"demo-graph\")\n\n// Add processing nodes\ngraph.AddNode(\"input\", \"Input Processing\", inputFunc)\ngraph.AddNode(\"llm\", \"LLM Processing\", llmFunc)\ngraph.AddNode(\"output\", \"Output Processing\", outputFunc)\n\n// Connect nodes\ngraph.AddEdge(\"input\", \"llm\", nil)\ngraph.AddEdge(\"llm\", \"output\", nil)\n\n// Execute graph\nresult, err := graph.Execute(ctx, initialState)\n</code></pre>"},{"location":"examples/ollama-integration/#6-streaming-response","title":"6. Streaming Response","text":"<pre><code>request := llm.CompletionRequest{\n    Messages: []llm.Message{\n        {Role: \"user\", Content: \"Count from 1 to 5\"},\n    },\n    Model:       \"gemma3:1b\",\n    Stream:      true,\n}\n\ncallback := func(chunk llm.CompletionResponse) error {\n    // Process streaming chunks\n    return nil\n}\n\nerr := llmManager.CompleteStream(ctx, \"ollama\", request, callback)\n</code></pre>"},{"location":"examples/ollama-integration/#configuration-options","title":"Configuration Options","text":""},{"location":"examples/ollama-integration/#llm-provider-configuration","title":"LLM Provider Configuration","text":"<pre><code>config := &amp;llm.ProviderConfig{\n    Type:        \"ollama\",\n    Endpoint:    \"http://localhost:11434\",  // Ollama server URL\n    Model:       \"gemma3:1b\",               // Model name\n    Temperature: 0.1,                       // Creativity (0.0-1.0)\n    MaxTokens:   200,                       // Response length limit\n    Timeout:     60 * time.Second,          // Request timeout\n}\n</code></pre>"},{"location":"examples/ollama-integration/#agent-configuration","title":"Agent Configuration","text":"<pre><code>config := &amp;agent.AgentConfig{\n    Name:          \"my-agent\",\n    Type:          agent.AgentTypeChat,     // Chat, ReAct, or Custom\n    Provider:      \"ollama\",\n    Model:         \"gemma3:1b\",\n    Temperature:   0.1,\n    MaxTokens:     100,\n    MaxIterations: 3,                       // For ReAct agents\n    Tools:         []string{\"calculator\"},  // Available tools\n    SystemPrompt:  \"You are a helpful AI assistant.\",\n}\n</code></pre>"},{"location":"examples/ollama-integration/#available-models","title":"Available Models","text":"<p>Ollama supports many open-source models. Popular choices for GoLangGraph:</p>"},{"location":"examples/ollama-integration/#small-models-good-for-development","title":"Small Models (Good for Development)","text":"<ul> <li>gemma3:1b - Google's Gemma 3 1B parameters</li> <li>phi3:mini - Microsoft's Phi-3 Mini</li> <li>llama3.2:1b - Meta's Llama 3.2 1B</li> </ul>"},{"location":"examples/ollama-integration/#medium-models-better-performance","title":"Medium Models (Better Performance)","text":"<ul> <li>gemma3:2b - Google's Gemma 3 2B parameters</li> <li>llama3.2:3b - Meta's Llama 3.2 3B</li> <li>phi3:medium - Microsoft's Phi-3 Medium</li> </ul>"},{"location":"examples/ollama-integration/#large-models-best-quality","title":"Large Models (Best Quality)","text":"<ul> <li>llama3.1:8b - Meta's Llama 3.1 8B</li> <li>gemma3:7b - Google's Gemma 3 7B</li> <li>mistral:7b - Mistral AI's 7B model</li> </ul> <pre><code># Pull different models\nollama pull gemma3:2b\nollama pull llama3.2:3b\nollama pull phi3:mini\n\n# List available models\nollama list\n</code></pre>"},{"location":"examples/ollama-integration/#performance-optimization","title":"Performance Optimization","text":""},{"location":"examples/ollama-integration/#model-selection","title":"Model Selection","text":"<ul> <li>Development: Use 1B-2B parameter models for fast iteration</li> <li>Production: Use 7B+ parameter models for better quality</li> <li>Resource Constraints: Smaller models require less RAM and CPU</li> </ul>"},{"location":"examples/ollama-integration/#configuration-tuning","title":"Configuration Tuning","text":"<pre><code>// For faster responses (less creative)\nTemperature: 0.0\n\n// For more creative responses\nTemperature: 0.7\n\n// For shorter responses\nMaxTokens: 50\n\n// For detailed responses\nMaxTokens: 500\n</code></pre>"},{"location":"examples/ollama-integration/#system-resources","title":"System Resources","text":"<ul> <li>RAM Requirements: </li> <li>1B models: ~2GB RAM</li> <li>3B models: ~4GB RAM</li> <li>7B models: ~8GB RAM</li> <li>CPU: Multi-core processors recommended</li> <li>GPU: Optional but significantly faster with NVIDIA GPUs</li> </ul>"},{"location":"examples/ollama-integration/#troubleshooting","title":"Troubleshooting","text":""},{"location":"examples/ollama-integration/#common-issues","title":"Common Issues","text":"<p>1. Ollama Not Running <pre><code># Check if Ollama is running\ncurl http://localhost:11434/api/tags\n\n# Start Ollama if not running\nollama serve\n</code></pre></p> <p>2. Model Not Found <pre><code># List available models\nollama list\n\n# Pull missing model\nollama pull gemma3:1b\n</code></pre></p> <p>3. Connection Errors <pre><code># Check Ollama logs\nollama logs\n\n# Verify endpoint\ncurl http://localhost:11434/api/version\n</code></pre></p> <p>4. Slow Responses - Use smaller models for faster responses - Reduce <code>MaxTokens</code> in configuration - Lower <code>Temperature</code> for more deterministic output</p>"},{"location":"examples/ollama-integration/#debug-mode","title":"Debug Mode","text":"<p>Enable debug logging in your Go application:</p> <pre><code>import \"github.com/sirupsen/logrus\"\n\n// Set log level to debug\nlogrus.SetLevel(logrus.DebugLevel)\n\n// Enable detailed LLM logging\nconfig.Debug = true\n</code></pre>"},{"location":"examples/ollama-integration/#integration-testing","title":"Integration Testing","text":"<p>The test script (<code>scripts/test-ollama-demo.sh</code>) provides comprehensive validation:</p>"},{"location":"examples/ollama-integration/#test-components","title":"Test Components","text":"<ol> <li>Ollama Installation Check</li> <li>Service Health Verification</li> <li>Model Availability Validation</li> <li>Basic Functionality Test</li> <li>Demo Execution</li> <li>Output Validation</li> </ol>"},{"location":"examples/ollama-integration/#running-tests","title":"Running Tests","text":"<pre><code># Full integration test\n./scripts/test-ollama-demo.sh\n\n# Check setup only\n./scripts/test-ollama-demo.sh check-only\n\n# Build only\n./scripts/test-ollama-demo.sh build-only\n\n# Run demo only\n./scripts/test-ollama-demo.sh run-only\n</code></pre>"},{"location":"examples/ollama-integration/#test-output","title":"Test Output","text":"<p>The script validates that all six demo components pass: - \u2705 Basic chat test passed! - \u2705 ReAct agent test passed! - \u2705 Multi-agent test passed! - \u2705 Quick builder test passed! - \u2705 Graph execution test passed! - \u2705 Streaming test passed!</p>"},{"location":"examples/ollama-integration/#production-considerations","title":"Production Considerations","text":""},{"location":"examples/ollama-integration/#security","title":"Security","text":"<ul> <li>Ollama runs locally, keeping data private</li> <li>No API keys or external connections required</li> <li>Consider firewall rules if exposing Ollama externally</li> </ul>"},{"location":"examples/ollama-integration/#scalability","title":"Scalability","text":"<ul> <li>Single Ollama instance serves multiple agents</li> <li>Consider load balancing for high-throughput applications</li> <li>Monitor resource usage and scale horizontally if needed</li> </ul>"},{"location":"examples/ollama-integration/#monitoring","title":"Monitoring","text":"<pre><code>// Add metrics collection\nimport \"github.com/prometheus/client_golang/prometheus\"\n\n// Track response times, error rates, etc.\nresponseTime := prometheus.NewHistogramVec(...)\nerrorRate := prometheus.NewCounterVec(...)\n</code></pre>"},{"location":"examples/ollama-integration/#deployment","title":"Deployment","text":"<pre><code># Docker Compose example\nversion: '3.8'\nservices:\n  ollama:\n    image: ollama/ollama:latest\n    ports:\n      - \"11434:11434\"\n    volumes:\n      - ollama_data:/root/.ollama\n    environment:\n      - OLLAMA_HOST=0.0.0.0\n\n  golanggraph:\n    build: .\n    depends_on:\n      - ollama\n    environment:\n      - OLLAMA_HOST=http://ollama:11434\n\nvolumes:\n  ollama_data:\n</code></pre>"},{"location":"examples/ollama-integration/#next-steps","title":"Next Steps","text":"<ol> <li>Explore More Models: Try different models for your use case</li> <li>Custom Tools: Implement domain-specific tools for your agents</li> <li>Advanced Workflows: Build complex multi-agent systems</li> <li>Performance Tuning: Optimize for your specific requirements</li> <li>Production Deployment: Scale and monitor your agent applications</li> </ol>"},{"location":"examples/ollama-integration/#resources","title":"Resources","text":"<ul> <li>Ollama Documentation</li> <li>Gemma Model Card</li> <li>GoLangGraph Examples</li> <li>Agent Configuration Guide</li> <li>Tool Development Guide </li> </ul>"},{"location":"getting-started/quick-start/","title":"Quick Start","text":"<p>Get up and running with GoLangGraph in just a few minutes! This guide will walk you through creating your first AI agent workflow.</p>"},{"location":"getting-started/quick-start/#prerequisites","title":"Prerequisites","text":"<ul> <li>Go 1.21 or later</li> <li>Basic familiarity with Go programming</li> <li>API key for an LLM provider (OpenAI, Ollama, etc.)</li> </ul>"},{"location":"getting-started/quick-start/#installation","title":"Installation","text":""},{"location":"getting-started/quick-start/#option-1-go-module-recommended","title":"Option 1: Go Module (Recommended)","text":"<pre><code># Initialize your Go module\ngo mod init my-agent-project\n\n# Add GoLangGraph dependency\ngo get github.com/piotrlaczkowski/GoLangGraph\n</code></pre>"},{"location":"getting-started/quick-start/#option-2-clone-and-build","title":"Option 2: Clone and Build","text":"<pre><code>git clone https://github.com/piotrlaczkowski/GoLangGraph.git\ncd GoLangGraph\ngo build ./cmd/golanggraph\n</code></pre>"},{"location":"getting-started/quick-start/#your-first-agent","title":"Your First Agent","text":"<p>Let's create a simple chat agent that can respond to user messages:</p>"},{"location":"getting-started/quick-start/#1-create-the-basic-agent","title":"1. Create the Basic Agent","text":"main.go<pre><code>package main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"log\"\n\n    \"github.com/piotrlaczkowski/GoLangGraph/pkg/builder\"\n    \"github.com/piotrlaczkowski/GoLangGraph/pkg/llm\"\n)\n\nfunc main() {\n    // Create a simple chat agent using the builder\n    agent := builder.OneLineChat(\"MyFirstAgent\")\n\n    // Configure with OpenAI (replace with your API key)\n    provider, err := llm.NewOpenAIProvider(llm.OpenAIConfig{\n        APIKey: \"your-openai-api-key\",\n        Model:  \"gpt-3.5-turbo\",\n    })\n    if err != nil {\n        log.Fatal(\"Failed to create OpenAI provider:\", err)\n    }\n\n    // Set the LLM provider for the agent\n    agent.SetLLMProvider(provider)\n\n    // Execute the agent with a simple message\n    ctx := context.Background()\n    response, err := agent.Execute(ctx, \"Hello! Tell me a joke.\")\n    if err != nil {\n        log.Fatal(\"Agent execution failed:\", err)\n    }\n\n    fmt.Printf(\"\ud83e\udd16 Agent Response: %s\\n\", response.Content)\n}\n</code></pre>"},{"location":"getting-started/quick-start/#2-run-your-agent","title":"2. Run Your Agent","text":"<pre><code># Set your OpenAI API key\nexport OPENAI_API_KEY=\"your-actual-api-key\"\n\n# Run the agent\ngo run main.go\n</code></pre> <p>Expected Output</p> <pre><code>\ud83e\udd16 Agent Response: Why don't scientists trust atoms? Because they make up everything!\n</code></pre>"},{"location":"getting-started/quick-start/#using-local-llm-ollama","title":"Using Local LLM (Ollama)","text":"<p>If you prefer to use a local LLM, you can use Ollama:</p>"},{"location":"getting-started/quick-start/#1-install-ollama","title":"1. Install Ollama","text":"<pre><code># On macOS\nbrew install ollama\n\n# On Linux\ncurl -fsSL https://ollama.com/install.sh | sh\n\n# Start Ollama service\nollama serve\n</code></pre>"},{"location":"getting-started/quick-start/#2-pull-a-model","title":"2. Pull a Model","text":"<pre><code># Pull a lightweight model\nollama pull llama3.2:1b\n\n# Or a more capable model\nollama pull llama3.2:3b\n</code></pre>"},{"location":"getting-started/quick-start/#3-update-your-code","title":"3. Update Your Code","text":"main.go<pre><code>package main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"log\"\n\n    \"github.com/piotrlaczkowski/GoLangGraph/pkg/builder\"\n    \"github.com/piotrlaczkowski/GoLangGraph/pkg/llm\"\n)\n\nfunc main() {\n    // Create a simple chat agent\n    agent := builder.OneLineChat(\"MyFirstAgent\")\n\n    // Configure with Ollama (local LLM)\n    provider, err := llm.NewOllamaProvider(llm.OllamaConfig{\n        BaseURL: \"http://localhost:11434\",\n        Model:   \"llama3.2:1b\",\n    })\n    if err != nil {\n        log.Fatal(\"Failed to create Ollama provider:\", err)\n    }\n\n    agent.SetLLMProvider(provider)\n\n    // Execute the agent\n    ctx := context.Background()\n    response, err := agent.Execute(ctx, \"Hello! Tell me about Go programming.\")\n    if err != nil {\n        log.Fatal(\"Agent execution failed:\", err)\n    }\n\n    fmt.Printf(\"\ud83e\udd16 Agent Response: %s\\n\", response.Content)\n}\n</code></pre>"},{"location":"getting-started/quick-start/#building-a-more-complex-workflow","title":"Building a More Complex Workflow","text":"<p>Let's create a more sophisticated agent that uses tools and state management:</p> advanced_agent.go<pre><code>package main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"log\"\n\n    \"github.com/piotrlaczkowski/GoLangGraph/pkg/agent\"\n    \"github.com/piotrlaczkowski/GoLangGraph/pkg/core\"\n    \"github.com/piotrlaczkowski/GoLangGraph/pkg/llm\"\n    \"github.com/piotrlaczkowski/GoLangGraph/pkg/tools\"\n)\n\nfunc main() {\n    // Create a new agent with configuration\n    config := agent.Config{\n        Name:        \"AdvancedAgent\",\n        Type:        \"tool\",\n        Description: \"An agent that can perform calculations and web searches\",\n        MaxSteps:    10,\n        Temperature: 0.7,\n    }\n\n    agent, err := agent.NewAgent(config)\n    if err != nil {\n        log.Fatal(\"Failed to create agent:\", err)\n    }\n\n    // Set up LLM provider\n    provider, err := llm.NewOpenAIProvider(llm.OpenAIConfig{\n        APIKey: \"your-openai-api-key\",\n        Model:  \"gpt-4\",\n    })\n    if err != nil {\n        log.Fatal(\"Failed to create LLM provider:\", err)\n    }\n    agent.SetLLMProvider(provider)\n\n    // Add tools to the agent\n    toolRegistry := tools.NewToolRegistry()\n\n    // Add calculator tool\n    calculator := tools.NewCalculatorTool()\n    toolRegistry.Register(\"calculator\", calculator)\n\n    // Add time tool\n    timeTool := tools.NewTimeTool()\n    toolRegistry.Register(\"time\", timeTool)\n\n    agent.SetToolRegistry(toolRegistry)\n\n    // Create initial state\n    state := core.NewBaseState()\n    state.Set(\"task\", \"Calculate the square root of 144 and tell me the current time\")\n\n    // Execute the agent\n    ctx := context.Background()\n    result, err := agent.Execute(ctx, state)\n    if err != nil {\n        log.Fatal(\"Agent execution failed:\", err)\n    }\n\n    fmt.Printf(\"\ud83e\udd16 Agent Result: %s\\n\", result.Get(\"response\"))\n}\n</code></pre>"},{"location":"getting-started/quick-start/#next-steps","title":"Next Steps","text":"<p>Congratulations! You've successfully created your first GoLangGraph agent. Here's what you can explore next:</p> <ul> <li> <p> Graph Workflows</p> <p>Learn how to create complex workflows with multiple nodes and conditional logic.</p> <p> Graph Workflows</p> </li> <li> <p> Tools &amp; Extensions</p> <p>Discover built-in tools and learn how to create custom tools for your agents.</p> <p> Tools Guide</p> </li> <li> <p> Persistence</p> <p>Add database persistence and build RAG applications with vector databases.</p> <p> Persistence Guide</p> </li> <li> <p> Examples</p> <p>Explore comprehensive examples including multi-agent systems and RAG implementations.</p> <p> Browse Examples</p> </li> </ul>"},{"location":"getting-started/quick-start/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/quick-start/#common-issues","title":"Common Issues","text":"<p>API Key Not Set</p> <p>If you get authentication errors, make sure your API key is correctly set: <pre><code>export OPENAI_API_KEY=\"your-actual-api-key\"\n</code></pre></p> <p>Ollama Connection Failed</p> <p>If Ollama connection fails, ensure the service is running: <pre><code>ollama serve\n# In another terminal\nollama list  # Check available models\n</code></pre></p> <p>Module Not Found</p> <p>If you get module import errors, ensure you're in a Go module directory: <pre><code>go mod init my-project\ngo mod tidy\n</code></pre></p>"},{"location":"getting-started/quick-start/#getting-help","title":"Getting Help","text":"<ul> <li>\ud83d\udcda Browse the full documentation</li> <li>\ud83d\udcac Join our Discord community</li> <li>\ud83d\udc1b Report issues on GitHub</li> <li>\ud83d\udcd6 Check out more examples </li> </ul>"}]}